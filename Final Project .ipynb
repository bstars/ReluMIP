{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30060ca3",
   "metadata": {},
   "source": [
    "# <center> EN.520.618: Modern Convex Optimization, Fall 2022, Final Project</center>\n",
    "## <center> Collaborator: Jiarui Wang, Chenyu Jin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d260012",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "> **Formulate an optimization problem for computing the “smallest” adversarial attack (measure in some arbitrary norm) that would change the predicted class of $x$ from $i$ to another class $j \\neq i$ (e.g., panda to gibon).**\n",
    "\n",
    "> In this problem we need to find the \"smallest\" perturbation such that the score of class j after perturbation is larger than the score of any other class $k \\neq j$, thus we can formulate the optimization problem below.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    min_{\\delta}.   & ~~ ||\\delta|| \\\\\n",
    "    s.t.            & ~~ f_j(x + \\delta) \\geq f_k(x+\\delta) ~~ \\forall k \\neq j\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edf968",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "> **Formulate an optimization problem for computing an adversarial attack that would change the label of $x$ from $i$ to another class $j \\neq i$ with the highest score gap, while constraining the magnitude of perturbation by $\\epsilon > 0$ (e.g., panda to gibon with a high confidence).**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    max_{\\delta}.   & ~~ f_j(x + \\delta) - f_i(x+\\delta) \\\\\n",
    "    s.t.            & ~~ ||\\delta|| \\leq \\epsilon \\\\\n",
    "    \\Updownarrow \\\\\n",
    "    min_{\\delta}.   & ~~ f_i(x+\\delta) - f_j(x + \\delta) \\\\\n",
    "    s.t.            & ~~ ||\\delta|| \\leq \\epsilon \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba284d",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "> **Formulate an optimization problem for computing an adversarial attack that attempt to change the label of $x$ from $i$ to another class $j \\neq i$ with highest score gap, while trying to keep the magnitude of perturbation minimal. How would you make a compromise between these two goals?**\n",
    "\n",
    "> We can add $||\\delta||$ as a regularization and control the magnitude by modifying the hyperparameter $\\lambda$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    min_{\\delta}.   & ~~   f_i(x+\\delta) -  f_j(x+\\delta)  + \\lambda ||\\delta||\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6ed51",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "> **Formulate an optimization problem for computing an adversarial attack that attempts to change the label of $x$ from $i$ to any class, while constraining the magnitude of perturbation by $\\epsilon$ (e.g., stop sign to any sign).**\n",
    "\n",
    "> This is a feasibility problem.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{find}. & ~~  \\delta \\\\\n",
    "    s.t. & ~~ \\max_{j\\neq i} f(x + \\delta) \\geq f_i(x + \\delta) \\\\\n",
    "        & ~~ ||\\delta|| \\leq \\epsilon\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ee7cd",
   "metadata": {},
   "source": [
    "## Problem 5 TO DO\n",
    "> **Propose an algorithm to solve the optimization problem in part 2 with perturbation budget $\\epsilon$ measured in $\\mathcal{l}_{\\infty}$ norm, i.e., $||\\delta||_{\\infty} \\leq \\epsilon$. Discuss the selection of the hyperparameters of your algorithm. What is a stopping criterion that warrants the change of label? What are the convergence guarantees? Clearly justify your answers.**\n",
    "\n",
    "> We can use subgradient method with Adam$^{[1]}$ acceleration. We choose step size $t=1e-3$, Adam parameter $\\beta_1=0.9$, $\\beta_2=0.99$. Once the objective of is negative, the score of the target label is larger than the score for all other classes,\n",
    "then the attack is success, and we terminate the iteration.\n",
    "\n",
    "> [1]: Kingma, Diederik P., and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a969e8",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "> **Implement the algorithm proposed in the previous part. Explore different hyperparameter choices that your algorithm has. The algorithm must return the resulting attack and the sequence of objective values.**\n",
    "\n",
    "> In our algorithm, when step size is large (e.g. 0.1), the objective values are unstable, and when it is small (e.g. 1e-5), the convergence is slow. $\\beta_1$ and $\\beta_2$ do not make much difference. The implementation is in ```impl2.gradient_attack```.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e860dae",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "> The implementaion is in ```impl2.load```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4202154",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimpl2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X,y \u001b[38;5;241m=\u001b[39m impl2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\Desktop\\JHU\\Fall 2022\\modern convex optimization\\Final_Project\\ReluMIP-main\\ReluMIP-main\\impl2.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcvxpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "import impl2\n",
    "\n",
    "X,y = impl2.load()\n",
    "for i in range(1):\n",
    "    impl2.plot(X[i].detach().numpy(), y[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
